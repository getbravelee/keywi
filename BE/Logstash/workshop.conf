input {
  jdbc {
    jdbc_driver_library => "C:\Users\SSAFY\Downloads\logstash-8.17.3\lib\mysql-connector-j-8.0.33.jar"
    jdbc_driver_class => "com.mysql.cj.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://localhost:3306/keywi"
    jdbc_user => "ssafy"
    jdbc_password => "ssafy"
    schedule => "* * * * *"  # 매 분마다 실행

    statement => "
      SELECT 
        f.post_id,
        f.content,
        f.hashtags,
        f.created_at,
        JSON_ARRAYAGG(
          JSON_OBJECT(
            'productId', p.product_id,
            'name', p.product_name,
            'description', p.description,
            'tags', p.description
          )
        ) AS tagged_products
      FROM posts f
      LEFT JOIN post_product_tag fp ON f.post_id = fp.post_id
      LEFT JOIN products p ON fp.product_id = p.product_id
      GROUP BY f.post_id
    "
  }
}

filter {
  json {
    source => "hashtags"
    target => "hashtags"
  }

  json {
    source => "tagged_products"
    target => "taggedProducts"
  }

  # 자동완성용 텍스트를 결합해서 새로운 필드 생성
  ruby {
    code => "
      auto_texts = []
      auto_texts << event.get('content') if event.get('content')
      auto_texts += event.get('hashtags') if event.get('hashtags')
      event.get('taggedProducts')&.each do |p|
        auto_texts << p['name'] if p['name']
        auto_texts << p['description'] if p['description']
      end
      event.set('autocomplete_texts', auto_texts.compact.uniq)
    "
  }
}

output {
  stdout { codec => rubydebug }

  # ✅ 원래대로 posts 인덱스에 전체 문서 저장
  elasticsearch {
    hosts => ["http://http://j12e202.p.ssafy.io/9200"]
    ssl => false
    user => "elastic"
    password => "zldnlWKd!"
    index => "posts"
    document_id => "%{post_id}"
  }

  # ✅ 자동완성 인덱스에 문장 단위로 분리해서 저장
  elasticsearch {
    hosts => ["http://http://j12e202.p.ssafy.io:9200"]
    ssl => false
    user => "elastic"
    password => "zldnlWkd!"
    index => "posts_autocomplete"
    document_id => "%{post_id}-%{+UNIX}"  # 중복 방지용
    # 메시지 분리
    codec => plain {
      format => "%{autocomplete_texts}"
    }
  }
}
# input {
#     # stdin{ }
#     tcp {
#         port => 9900
#     }
# }

# filter {
    
# }

# output {
#     stdout { }
#     elasticsearch {
#         hosts => ["https://elastic-1:9200"]
#         ssl_enabled => true
#         cacert => "/etc/logstash/certs/http_ca.crt"
#         user => "elastic"
#         password => "pv2O8hpvkZDaCMF33My+"
#         index => "logstash-%{+YYYY.MM.dd}"
#     }
# }
